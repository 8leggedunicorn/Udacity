{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "DATADIR = \"DataWranglingwithMongoDB/\"\n",
    "DATAFILE = \"beatles-diskography.csv\"\n",
    "DATAFILE = os.path.join(DATADIR, DATAFILE)\n",
    "\n",
    "def parse_file(datafile):\n",
    "    data = []\n",
    "    num = 0\n",
    "    with open(datafile, encoding='utf-8', mode='r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip('\\n') \n",
    "            if num == 0:\n",
    "                Keys = line.split(',')\n",
    "            if num > 0 and num < 11:\n",
    "                Values = line.split(',')\n",
    "                beatles = dict(zip(Keys, Values))\n",
    "                data.append(beatles) \n",
    "            num += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = parse_file(DATAFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is as follows:\n",
    "- read the provided Excel file\n",
    "- find and return the min, max and average values for the COAST region\n",
    "- find and return the time value for the min and max entries\n",
    "- the time values should be returned as Python tuples\n",
    "\n",
    "Please see the test function for the expected return format\n",
    "\"\"\"\n",
    "\n",
    "import xlrd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from zipfile import ZipFile\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "datadir = \"./DataWranglingwithMongoDB/\"\n",
    "\n",
    "datafile = os.path.join(datadir,datafile)\n",
    "\n",
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile.rsplit('.',1)[0]), 'r') as myzip:\n",
    "        myzip.extractall(datadir)\n",
    "       \n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    ### example on how you can get the data\n",
    "    #sheet_data = [[sheet.cell_value(r, col) for col in range(sheet.ncols)] for r in range(sheet.nrows)]\n",
    "\n",
    "    ### other useful methods:\n",
    "    print(\"\\nROWS, COLUMNS, and CELLS:\")\n",
    "    print(\"Number of rows in the sheet:\")\n",
    "    print(sheet.nrows)\n",
    "    print(\"Type of data in cell (row 3, col 2):\") \n",
    "    print(sheet.cell_type(3, 2))\n",
    "    print (\"Value in cell (row 3, col 2):\", )\n",
    "    print(sheet.cell_value(3, 2))\n",
    "    print(\"Get a slice of values in column 2 - COAST from rows 1-3:\")\n",
    "\n",
    "    coast_vals = sheet.col_values(1, start_rowx=1)\n",
    "    \n",
    "    print\n",
    "    print(\"\\nDATES:\")\n",
    "    print(\"Type of data in cell (row 1, col 0):\")\n",
    "    print(sheet.cell_type(1, 0))\n",
    "    exceltime = sheet.cell_value(1, 0)\n",
    "    print(\"Time in Excel format:\",)\n",
    "    print(exceltime)\n",
    "    print(\"Convert time to a Python datetime tuple, from the Excel float:\")\n",
    "    print(xlrd.xldate_as_tuple(exceltime, 0))\n",
    "    \n",
    "    \n",
    "    data = {\n",
    "            'maxtime': (0, 0, 0, 0, 0, 0),\n",
    "            'maxvalue': 0,\n",
    "            'mintime': (0, 0, 0, 0, 0, 0),\n",
    "            'minvalue': 0,\n",
    "            'avgcoast': 0\n",
    "    }\n",
    "    coast_vals = np.array(coast_vals)\n",
    "    \n",
    "    data['avgcoast'] = np.average(coast_vals)\n",
    "    data['maxvalue'] = np.max(coast_vals)\n",
    "    data['minvalue'] = np.min(coast_vals)\n",
    "    \n",
    "    maxidx = coast_vals.argmax()\n",
    "    minidx = coast_vals.argmin()\n",
    "    maxtime = xlrd.xldate_as_tuple(sheet.cell_value(maxidx + 1, 0),0)\n",
    "    mintime = xlrd.xldate_as_tuple(sheet.cell_value(minidx + 1, 0),0)\n",
    "    \n",
    "    data['maxtime'] = maxtime\n",
    "    data['mintime'] = mintime\n",
    "    \n",
    "    print(data)\n",
    "    return data\n",
    "\n",
    "open_zip(datafile)\n",
    "data = parse_file(datafile)\n",
    "#print('{0}.zip'.format(datafile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "\n",
    "    assert data['maxtime'] == (2013, 8, 13, 17, 0, 0)\n",
    "    assert round(data['maxvalue'], 10) == round(18779.02551, 10)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To experiment with this code freely you will have to run this code locally.\n",
    "# Take a look at the main() function for an example of how to use the code.\n",
    "# We have provided example json output in the other code editor tabs for you to\n",
    "# look at, but you will not be able to run any queries through our UI.\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "BASE_URL = \"http://musicbrainz.org/ws/2/\"\n",
    "ARTIST_URL = BASE_URL + \"artist/\"\n",
    "\n",
    "# query parameters are given to the requests.get function as a dictionary; this\n",
    "# variable contains some starter parameters.\n",
    "query_type = {  \"simple\": {},\n",
    "                \"atr\": {\"inc\": \"aliases+tags+ratings\"},\n",
    "                \"aliases\": {\"inc\": \"aliases\"},\n",
    "                \"releases\": {\"inc\": \"releases\"}}\n",
    "\n",
    "\n",
    "def query_site(url, params, uid=\"\", fmt=\"json\"):\n",
    "    # This is the main function for making queries to the musicbrainz API.\n",
    "    # A json document should be returned by the query.\n",
    "    params[\"fmt\"] = fmt\n",
    "    r = requests.get(url + uid, params=params)\n",
    "    print(\"requesting\", r.url)\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "\n",
    "\n",
    "def query_by_name(url, params, name):\n",
    "    # This adds an artist name to the query parameters before making\n",
    "    # an API call to the function above.\n",
    "    params[\"query\"] = \"artist:\" + name\n",
    "    return query_site(url, params)\n",
    "\n",
    "\n",
    "def pretty_print(data, indent=4):\n",
    "    # After we get our output, we can format it to be more readable\n",
    "    # by using this function.\n",
    "    if type(data) == dict:\n",
    "        print(json.dumps(data, indent=indent, sort_keys=True))\n",
    "    else:\n",
    "        print(data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    Modify the function calls and indexing below to answer the questions on\n",
    "    the next quiz. HINT: Note how the output we get from the site is a\n",
    "    multi-level JSON document, so try making print statements to step through\n",
    "    the structure one level at a time or copy the output to a separate output\n",
    "    file.\n",
    "    '''\n",
    "    results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Queen\")\n",
    "    pretty_print(results)\n",
    "\n",
    "    artist_id = results[\"artists\"][1][\"id\"]\n",
    "    print (\"\\nARTIST:\")\n",
    "    pretty_print(results[\"artists\"][1])\n",
    "\n",
    "    artist_data = query_site(ARTIST_URL, query_type[\"releases\"], artist_id)\n",
    "    releases = artist_data[\"releases\"]\n",
    "    print(\"\\nONE RELEASE:\")\n",
    "    pretty_print(releases[0], indent=2)\n",
    "    release_titles = [r[\"title\"] for r in releases]\n",
    "\n",
    "    print(\"\\nALL TITLES:\")\n",
    "    for t in release_titles:\n",
    "        print (t)\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"One Direction\")\n",
    "print([ artist[\"name\"] for artist in results[\"artists\"] ])\n",
    "#pretty_print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[\"artists\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef test():\\n    datafile = os.path.join(DATADIR, DATAFILE)\\n    name, data = parse_file(datafile)\\n\\n    assert name == \"MOUNTAIN VIEW MOFFETT FLD NAS\"\\n    assert data[0][1] == \"01:00\"\\n    assert data[2][0] == \"01/01/2005\"\\n    assert data[2][5] == \"2\"\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Your task is to process the supplied file and use the csv module to extract data from it.\n",
    "The data comes from NREL (National Renewable Energy Laboratory) website. Each file\n",
    "contains information from one meteorological station, in particular - about amount of\n",
    "solar and wind energy for each hour of day.\n",
    "\n",
    "Note that the first line of the datafile is neither data entry, nor header. It is a line\n",
    "describing the data source. You should extract the name of the station from it.\n",
    "\n",
    "The data should be returned as a list of lists (not dictionaries).\n",
    "You can use the csv modules \"reader\" method to get data in such format.\n",
    "Another useful method is next() - to get the next line from the iterator.\n",
    "You should only change the parse_file function.\n",
    "\"\"\"\n",
    "import csv\n",
    "import os\n",
    "\n",
    "DATADIR = \"./data/\"\n",
    "DATAFILE = \"745090.csv\"\n",
    "\n",
    "def parse_file(datafile):\n",
    "    name = \"\"\n",
    "    data = []\n",
    "    with open(datafile,mode  = 'rt') as f:\n",
    "        reader = csv.reader(f)\n",
    "        name = next(reader).split()\n",
    "        iter = 0\n",
    "    #    for row in reader:\n",
    "    #        if iter == 0:\n",
    "    #            name = row\n",
    "    #            print(name)\n",
    "    #        else:\n",
    "    #        print(line[0])\n",
    "    #    iter += 1\n",
    "    #    pass\n",
    "    # Do not change the line below\n",
    "    return (name, data)\n",
    "\n",
    "\"\"\"\n",
    "def test():\n",
    "    datafile = os.path.join(DATADIR, DATAFILE)\n",
    "    name, data = parse_file(datafile)\n",
    "\n",
    "    assert name == \"MOUNTAIN VIEW MOFFETT FLD NAS\"\n",
    "    assert data[0][1] == \"01:00\"\n",
    "    assert data[2][0] == \"01/01/2005\"\n",
    "    assert data[2][5] == \"2\"\n",
    "\"\"\"\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datafile = os.path.join(DATADIR,DATAFILE)\n",
    "name = parse_file(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['745090', 'MOUNTAIN VIEW MOFFETT FLD NAS', 'CA', '-8.0', '37.400', '-122.050', '12'], [])\n"
     ]
    }
   ],
   "source": [
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
